{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Capstone Project – The Battle of neighborhoods (Week1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A description of the problem and a discussion of the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 - Description of the problem: \n",
    "\n",
    "People starting new businesses have different requirements and studies to conduct before launching their project. To start a restaurant, people need to find the right place. The definition of right place incorporate different aspects; places with high people density, not flooded with restaurant, and including other facilities that might lead people to think about food. For instance, malls, schools and companies incorporate people doing different activities, yet, all might need to have a meal at a certain point of their day. Doing, the proper research might help the business owner locate contender boroughs in a city where the busines will have much more chances to succeed.\n",
    "\n",
    "##### 2- Business understanding: \n",
    "\n",
    "Given the reality of the targeted business and its success requirements, Can we provide a short list of boroughs to help business owner decide where to start its business?\n",
    "\n",
    "##### 3 - Interested people: \n",
    "\n",
    "This problem is very interesting for all the people deciding to start their own restaurant. This approach can be also adopted for other kind of business like gyms and entertainment services.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A description of the data and how it will be used to solve the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data is the most important element of any data science project, almost 60% of relevancy of any machine learning model is related to the relevancy of the dataset and the different features it incorporates.\n",
    "\n",
    "###### For our use case, the data needed can be summarized as follow: \n",
    "\n",
    "1-\tFor a targeted city, The boroughs and neighborhoods and their corresponding locations.\n",
    "\n",
    "2-\tList of schools and companies for each borough and neighborhood.\n",
    "\n",
    "3-\tList of entertainment venues for each borough and neighbors (Malls, Gyms, gaming rooms …)\n",
    "\n",
    "4-\tList of restaurants for each borough and neighborhood\n",
    "\n",
    "Assuming the guy is willing to open a restaurant in Toronto, we will scrape the data of postal codes of the city of Toronto and get the location of the different boroughs, for each we will use the foursquare to explore the location and get different venues in it. Later, we will filter the venues to extract those that will help us in our analysis such as restaurants, stations, malls and other entertainment facilities that usually attract people.\n",
    "\n",
    "Processing this data, will help us identify subset of boroughs where we have the most of facilities that might lead people to go and eat, this also should be tempered by the number of restaurant in the borough so that you don’t open your business in a place already crowded with restaurants.\n",
    "\n",
    "###### Data sources: \n",
    "1 - Toronto PostCOde: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n",
    "\n",
    "2 - Foursquare API\n",
    "\n",
    "###### Data usage steps:\n",
    "1 - Location of the targeted city and visualize using map and folium \n",
    "\n",
    "2 - Beautifulsoup and scrap data related to borough and neighboros of the atrgeted city \n",
    "\n",
    "3 - use open dataset to fetch the location of each neighbor \n",
    "\n",
    "4 - Foursquare to explore each neighbor \n",
    "\n",
    "5 - extract usefull venues in neighbor e.g., restourants, hotels, gyms, parks, stores \n",
    "\n",
    "6 - aggregate venues by neighbors and derive scores to highlight the relevancy of the neighbor \n",
    "\n",
    "7 - derive subset of neighbors per borough with the highest prospects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "#!pip install geocoder\n",
    "#import geocoder \n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lets first see the targeted city on the map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toronto\n",
    "latitude=43.653226\n",
    "longitude=-79.3831843\n",
    "venues_map = folium.Map(location=[latitude, longitude], zoom_start=13) # generate map centred around the Conrad Hotel\n",
    "\n",
    "venues_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lets get the postalcodes for the different borough and neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets assign the url to the wiki page and insatntiate a beautifulsoup object with the get request output\n",
    "url ='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "toronto_wiki = requests.get(url).text\n",
    "soup_object_toronto=bs4.BeautifulSoup(toronto_wiki,'lxml')\n",
    "#first we locate the table \n",
    "table=soup_object_toronto.find('table')\n",
    "\n",
    "#we parse the table and extract only three variables - 'PostalCode','Borough','Neighborhood'\n",
    "\n",
    "Toronto_post_bor_neigh = []\n",
    "for row in table.findAll('td'):\n",
    "    cell = {}\n",
    "    if row.span.text=='Not assigned':\n",
    "        pass\n",
    "    else:\n",
    "        cell['PostalCode'] = row.p.text[:3]\n",
    "        cell['Borough'] = (row.span.text).split('(')[0]\n",
    "        cell['Neighborhood'] = (((((row.span.text).split('(')[1]).strip(')')).replace(' /',',')).replace(')',' ')).strip(' ')\n",
    "        Toronto_post_bor_neigh.append(cell)\n",
    "#we creata dataframe from the extracted nisted list\n",
    "df=pd.DataFrame(Toronto_post_bor_neigh)\n",
    "#preprocessing\n",
    "df1 = df[df.Borough != 'Not assigned']\n",
    "df2 = df1.groupby(['PostalCode','Borough'], sort=False).agg(', '.join)\n",
    "df2.reset_index(inplace=True)\n",
    "\n",
    "df2['Neighborhood'] = np.where(df2['Neighborhood'] == 'Not assigned',df2['Borough'], df2['Neighborhood'])\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lets add the location of each neigborhood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## use the csv file \n",
    "#load the csv in daatframe\n",
    "la_lo_csv = pd.read_csv('https://cocl.us/Geospatial_data')\n",
    "\n",
    "# now lets match the postal Code with the PostcodeID and get a merged dataframe\n",
    "df_lo_la_toronto = pd.merge(df2, la_lo_csv, left_on='PostalCode', right_on='Postal Code')\n",
    "df_lo_la_toronto.head(10)\n",
    "#lets drop the Post code its just duplicated \n",
    "df_lo_la_toronto=df_lo_la_toronto.drop('Postal Code',axis=1)\n",
    "df_lo_la_toronto.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lets use foursquare ond explore the different neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'TJI0OMJ0INFZVVD1SQBTJQTYXWKYBJXG4J4OD4WPGPOUKA4P' # your Foursquare ID\n",
    "CLIENT_SECRET = '1QLSVKLKZDOVWZCY2LUMNNTFJKOMONH2ZP334AVRHT4XE1IA' # your Foursquare Secret\n",
    "ACCESS_TOKEN = 'VENHRI5EXTAK5QFACKIRNJOCK5LRXTV0RXS2UGKCJAEZBIQ0' # your FourSquare Access Token\n",
    "VERSION = '20180604'\n",
    "LIMIT = 100\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = 43.667856\n",
    "longitude = -79.532242\n",
    "radius=1000\n",
    "neighborhood_url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, radius, LIMIT)\n",
    "neighborhood_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(neighborhood_url).json()\n",
    "'There are {} in the nieghborhood.'.format(len(results['response']['groups'][0]['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = results['response']['groups'][0]['items']\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### lets process the json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # library to handle JSON files\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize\n",
    "dataframe = json_normalize(items) # flatten JSON\n",
    "\n",
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories'] + [col for col in dataframe.columns if col.startswith('venue.location.')] + ['venue.id']\n",
    "dataframe_filtered = dataframe.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "dataframe_filtered['venue.categories'] = dataframe_filtered.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "dataframe_filtered.columns = [col.split('.')[-1] for col in dataframe_filtered.columns]\n",
    "\n",
    "dataframe_filtered['Borough'] = 'North York'\n",
    "dataframe_filtered['Neighborhood'] = 'Lawrence Manor, Lawrence Heights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### after getting all the venues for each neighborhood now lets remove the non related features and keep only the interesting information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pure = dataframe_filtered[['name','categories','lat','lng','distance','Borough','Neighborhood']]\n",
    "data_pure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude=43.653226\n",
    "longitude=-79.3831843\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi in zip(data_pure['lat'], data_pure['lng'], data_pure['Neighborhood']):\n",
    "    #label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get venues for each neighborhood\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each nieghborhood get most freq \n",
    "\n",
    "# one hot encoding\n",
    "manhattan_onehot = pd.get_dummies(df_man[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "manhattan_onehot['Neighborhood'] = df_man['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [manhattan_onehot.columns[-1]] + list(manhattan_onehot.columns[:-1])\n",
    "manhattan_onehot = manhattan_onehot[fixed_columns]\n",
    "\n",
    "manhattan_onehot.head()\n",
    "\n",
    "\n",
    "num_top_venues = 5\n",
    "\n",
    "for hood in manhattan_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = manhattan_grouped[manhattan_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean freq of each categor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
